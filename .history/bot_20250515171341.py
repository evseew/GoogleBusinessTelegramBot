import sys
import os
import time # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è time.time()
import asyncio
import logging
import datetime # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è datetime.datetime, datetime.timedelta
import glob
import io
from io import BytesIO
import json
import re
import signal # –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
import shutil
from asyncio import Lock
from collections import defaultdict # –î–ª—è user_processing_locks
from typing import Optional, List, Dict, Any

# --- Dependency Imports ---
import openai
import chromadb
from dotenv import load_dotenv
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import docx
import PyPDF2

from aiogram import Bot, Dispatcher, Router, types as aiogram_types, F
from aiogram.filters import Command
from aiogram.enums import ChatAction # –î–ª—è —Å—Ç–∞—Ç—É—Å–∞ "–ø–µ—á–∞—Ç–∞–µ—Ç"

# LangChain components
from langchain_openai import OpenAIEmbeddings # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é, –Ω–æ –º–æ–∂–µ—Ç –ø–æ–Ω–∞–¥–æ–±–∏—Ç—å—Å—è –µ—Å–ª–∏ OpenAI API –∫–ª–∏–µ–Ω—Ç –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter
from langchain_core.documents import Document # Langchain Document

# --- Load Environment Variables ---
load_dotenv()

print(f"DEBUG: OPENAI_API_KEY –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–æ getenv: {os.environ.get('OPENAI_API_KEY')}")

# --- Configuration ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ASSISTANT_ID = os.getenv("ASSISTANT_ID")
SERVICE_ACCOUNT_FILE = os.getenv("SERVICE_ACCOUNT_FILE", 'service-account-key.json')
FOLDER_ID = os.getenv("GOOGLE_DRIVE_FOLDER_ID")

try:
    ADMIN_USER_ID_STR = os.getenv("ADMIN_USER_ID")
    if not ADMIN_USER_ID_STR:
        raise ValueError("ADMIN_USER_ID –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
    ADMIN_USER_ID = int(ADMIN_USER_ID_STR)
except (ValueError, TypeError) as e:
    logging.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ADMIN_USER_ID –≤ .env: {e}")
    sys.exit(1)

try:
    manager_ids_str = os.getenv("MANAGER_USER_IDS", "")
    MANAGER_USER_IDS = [int(id_str.strip()) for id_str in manager_ids_str.split(',') if id_str.strip()]
except (ValueError, TypeError) as e:
    logging.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è MANAGER_USER_IDS –≤ .env: {e}")
    sys.exit(1)

MESSAGE_BUFFER_SECONDS = int(os.getenv("MESSAGE_BUFFER_SECONDS", "4"))
LOGS_DIR = os.getenv("LOGS_DIR", "./logs/context_logs_telegram")
SILENCE_STATE_FILE = os.getenv("TELEGRAM_SILENCE_STATE_FILE", "telegram_silence_state.json")

VECTOR_DB_BASE_PATH = os.getenv("VECTOR_DB_BASE_PATH_TELEGRAM", "./local_vector_db_telegram")
ACTIVE_DB_INFO_FILE = os.getenv("ACTIVE_DB_INFO_FILE_TELEGRAM", "active_db_path_telegram.txt")
OPENAI_EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-large")
try:
    _dim_str = os.getenv("OPENAI_EMBEDDING_DIMENSIONS")
    OPENAI_EMBEDDING_DIMENSIONS = int(_dim_str) if _dim_str and _dim_str.lower() != 'none' else None
except ValueError:
    logging.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ OPENAI_EMBEDDING_DIMENSIONS ('{_dim_str}'), –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è None.")
    OPENAI_EMBEDDING_DIMENSIONS = None

CHROMA_COLLECTION_NAME = os.getenv("CHROMA_COLLECTION_NAME_TELEGRAM", "documents_telegram")
RELEVANT_CONTEXT_COUNT = int(os.getenv("RELEVANT_CONTEXT_COUNT", "3"))
OPENAI_RUN_TIMEOUT_SECONDS = int(os.getenv("OPENAI_RUN_TIMEOUT_SECONDS", "90"))
LOG_RETENTION_SECONDS = int(os.getenv("LOG_RETENTION_SECONDS_TELEGRAM", "86400")) # 24 —á–∞—Å–∞
USE_VECTOR_STORE_STR = os.getenv("USE_VECTOR_STORE_TELEGRAM", "True")
USE_VECTOR_STORE = USE_VECTOR_STORE_STR.lower() == 'true'

MESSAGE_LIFETIME_DAYS = int(os.getenv("MESSAGE_LIFETIME_DAYS", "100")) 
MESSAGE_LIFETIME = datetime.timedelta(days=MESSAGE_LIFETIME_DAYS)


# --- Validate Configuration ---
required_vars = {
    "TELEGRAM_BOT_TOKEN": TELEGRAM_BOT_TOKEN,
    "OPENAI_API_KEY": OPENAI_API_KEY,
    "ASSISTANT_ID": ASSISTANT_ID,
    "FOLDER_ID": FOLDER_ID,
    "ADMIN_USER_ID": ADMIN_USER_ID
}
missing_vars_list = [name for name, value in required_vars.items() if not value and value != 0]
if missing_vars_list:
    logging.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {', '.join(missing_vars_list)}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª.")
    sys.exit(1)

# --- Setup Logging ---
os.makedirs(LOGS_DIR, exist_ok=True)
logging.basicConfig(
    level=logging.INFO, # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ DEBUG –¥–ª—è –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    format='%(asctime)s - %(levelname)s - %(name)s - %(funcName)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# --- Initialize API Clients ---
try:
    openai_client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
    logger.info("–ö–ª–∏–µ–Ω—Ç OpenAI Async –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except Exception as e:
    logger.critical(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç OpenAI: {e}", exc_info=True)
    sys.exit(1)

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
router = Router()

# --- Global State (In-Memory) ---
user_threads: Dict[int, str] = {} 
user_messages: Dict[int, List[Dict[str, Any]]] = {} 

pending_messages: Dict[int, List[str]] = {}  
user_message_timers: Dict[int, asyncio.Task] = {}  
user_processing_locks: defaultdict[int, asyncio.Lock] = defaultdict(asyncio.Lock)

chat_silence_state: Dict[int, bool] = {} 

# --- Vector Store (ChromaDB) ---
vector_collection: Optional[chromadb.api.models.Collection.Collection] = None

def _get_active_db_full_path_telegram() -> Optional[str]: # Renamed from _get_active_db_subpath_telegram
    try:
        active_db_info_filepath = os.path.join(VECTOR_DB_BASE_PATH, ACTIVE_DB_INFO_FILE)
        if os.path.exists(active_db_info_filepath):
            with open(active_db_info_filepath, "r", encoding="utf-8") as f:
                active_subdir_or_fullname = f.read().strip() 
            
            if not active_subdir_or_fullname:
                logger.warning(f"–§–∞–π–ª '{ACTIVE_DB_INFO_FILE}' (TG) –ø—É—Å—Ç.")
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª–Ω—ã–º –ø—É—Ç–µ–º –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º
            # –≠—Ç–æ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –µ—Å–ª–∏ —Ä–∞–Ω—å—à–µ —Å–æ—Ö—Ä–∞–Ω—è–ª—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
            potential_full_path = active_subdir_or_fullname
            if not os.path.isabs(potential_full_path): # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å
                 potential_full_path = os.path.join(VECTOR_DB_BASE_PATH, active_subdir_or_fullname)
            
            if os.path.isdir(potential_full_path): 
                logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –∞–∫—Ç–∏–≤–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ë–î (TG): '{potential_full_path}'")
                return potential_full_path
            else: 
                logger.warning(f"–í —Ñ–∞–π–ª–µ '{ACTIVE_DB_INFO_FILE}' (TG) —É–∫–∞–∑–∞–Ω –ø—É—Ç—å '{active_subdir_or_fullname}', –Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è '{potential_full_path}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
                return None
        else: 
            logger.info(f"–§–∞–π–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–∫—Ç–∏–≤–Ω–æ–π –ë–î '{ACTIVE_DB_INFO_FILE}' (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–∫—Ç–∏–≤–Ω–æ–π –ë–î (TG): {e}", exc_info=True)
        return None

async def _initialize_active_vector_collection_telegram():
    global vector_collection
    active_db_full_path = _get_active_db_full_path_telegram()
    if active_db_full_path:
        try:
            def _init_chroma():
                chroma_client_init = chromadb.PersistentClient(path=active_db_full_path)
                return chroma_client_init.get_or_create_collection(
                    name=CHROMA_COLLECTION_NAME,
                )
            vector_collection = await asyncio.to_thread(_init_chroma)
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ ChromaDB (TG): '{active_db_full_path}'. –ö–æ–ª–ª–µ–∫—Ü–∏—è: '{CHROMA_COLLECTION_NAME}'.")
            if vector_collection:
                count = await asyncio.to_thread(vector_collection.count)
                logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∞–∫—Ç–∏–≤–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ (TG) –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ: {count}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB (TG) –¥–ª—è –ø—É—Ç–∏ '{active_db_full_path}': {e}. –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.", exc_info=True)
            vector_collection = None
    else:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ë–î (TG). –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        vector_collection = None

# --- Google Drive ---
drive_service_instance = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ main

def get_drive_service_sync(): 
    global drive_service_instance
    if drive_service_instance:
        return drive_service_instance
    try:
        credentials = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        drive_service_instance = build('drive', 'v3', credentials=credentials)
        logger.info("–°–µ—Ä–≤–∏—Å Google Drive –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ).")
        return drive_service_instance
    except FileNotFoundError:
        logger.error(f"–§–∞–π–ª –∫–ª—é—á–∞ Google Service Account –Ω–µ –Ω–∞–π–¥–µ–Ω: {SERVICE_ACCOUNT_FILE}")
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–µ—Ä–≤–∏—Å–∞ Google Drive: {e}", exc_info=True)
        return None

def _download_file_content_sync(service, file_id, export_mime_type=None): 
    if export_mime_type:
        request = service.files().export_media(fileId=file_id, mimeType=export_mime_type)
    else:
        request = service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done: # Corrected loop condition
        status, done = downloader.next_chunk()
        if status: logger.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ {file_id} (TG): {int(status.progress() * 100)}%.")
    fh.seek(0)
    return fh

def read_data_from_drive_sync() -> List[Dict[str,str]]: 
    service = get_drive_service_sync()
    if not service:
        logger.error("–ß—Ç–µ–Ω–∏–µ –∏–∑ Google Drive (TG) –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ: —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        return []
    
    result_docs: List[Dict[str,str]] = []
    try:
        files_response = service.files().list(
            q=f"'{FOLDER_ID}' in parents and trashed=false",
            fields="files(id, name, mimeType)", pageSize=1000
        ).execute()
        files = files_response.get('files', [])
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(files)} —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ Google Drive (TG).")

        downloader_map = {
            'application/vnd.google-apps.document': lambda s, f_id: download_google_doc_sync(s, f_id),
            'application/pdf': lambda s, f_id: download_pdf_sync(s, f_id),
            'application/vnd.openxmlformats-officedocument.wordprocessingml.document': lambda s, f_id: download_docx_sync(s, f_id),
            'text/plain': lambda s, f_id: download_text_sync(s, f_id),
            'text/markdown': lambda s, f_id: download_text_sync(s, f_id),
        }

        for file_item in files:
            file_id, mime_type, file_name = file_item['id'], file_item['mimeType'], file_item['name']
            if mime_type in downloader_map:
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ (TG): '{file_name}' (ID: {file_id}, Type: {mime_type})")
                try:
                    content_str = downloader_map[mime_type](service, file_id)
                    if content_str and content_str.strip():
                        result_docs.append({'name': file_name, 'content': content_str})
                        logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω —Ñ–∞–π–ª (TG): '{file_name}' ({len(content_str)} —Å–∏–º–≤)")
                    else:
                        logger.warning(f"–§–∞–π–ª '{file_name}' (TG) –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–µ–Ω—Ç.")
                except Exception as e_read_file:
                    logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ '{file_name}' (TG): {e_read_file}", exc_info=True)
            else:
                logger.debug(f"–§–∞–π–ª '{file_name}' (TG) –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø ({mime_type}).")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∏–∑ Google Drive (TG): {e}", exc_info=True)
        return []
    logger.info(f"–ß—Ç–µ–Ω–∏–µ –∏–∑ Google Drive (TG) –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(result_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
    return result_docs

def download_google_doc_sync(service, file_id) -> str: 
    fh = _download_file_content_sync(service, file_id, export_mime_type='text/plain')
    return fh.getvalue().decode('utf-8', errors='ignore')

def download_pdf_sync(service, file_id) -> str: 
    fh = _download_file_content_sync(service, file_id)
    try:
        pdf_reader = PyPDF2.PdfReader(fh)
        return "".join(page.extract_text() + "\n" for page in pdf_reader.pages if page.extract_text())
    except Exception as e:
         logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF (ID: {file_id}, TG): {e}", exc_info=True)
         return ""

def download_docx_sync(service, file_id) -> str: 
    fh = _download_file_content_sync(service, file_id)
    try:
        doc = docx.Document(fh)
        return "\n".join(paragraph.text for paragraph in doc.paragraphs if paragraph.text)
    except Exception as e:
         logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX (ID: {file_id}, TG): {e}", exc_info=True)
         return ""

def download_text_sync(service, file_id) -> str: 
    fh = _download_file_content_sync(service, file_id)
    try:
        return fh.getvalue().decode('utf-8')
    except UnicodeDecodeError:
         logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å {file_id} (TG) –∫–∞–∫ UTF-8, –ø—Ä–æ–±—É–µ–º cp1251.")
         try: return fh.getvalue().decode('cp1251', errors='ignore')
         except Exception as e_decode:
              logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å {file_id} (TG): {e_decode}")
              return ""

# --- Helper Functions ---
async def get_or_create_thread(user_id: int) -> Optional[str]:
    if user_id in user_threads:
        thread_id = user_threads[user_id]
        try:
            await openai_client.beta.threads.messages.list(thread_id=thread_id, limit=1)
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–¥ {thread_id} –¥–ª—è user_id={user_id} (TG)")
            return thread_id
        except openai.NotFoundError:
            logger.warning(f"–¢—Ä–µ–¥ {thread_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ OpenAI –¥–ª—è user_id={user_id} (TG). –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π.")
            if user_id in user_threads: del user_threads[user_id]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ç—Ä–µ–¥—É {thread_id} –¥–ª—è user_id={user_id} (TG): {e}. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π.")
            if user_id in user_threads: del user_threads[user_id]

    try:
        logger.info(f"–°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–¥ –¥–ª—è user_id={user_id} (TG)...")
        thread = await openai_client.beta.threads.create()
        thread_id = thread.id
        user_threads[user_id] = thread_id
        user_messages[user_id] = [] 
        logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ç—Ä–µ–¥ {thread_id} –¥–ª—è user_id={user_id} (TG)")
        return thread_id
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ —Ç—Ä–µ–¥–∞ –¥–ª—è user_id={user_id} (TG): {e}", exc_info=True)
        return None

async def cleanup_old_messages_in_memory(): 
    current_time = datetime.datetime.now()
    for user_id in list(user_messages.keys()):
        async with user_processing_locks[user_id]:
            if user_id in user_messages:
                user_messages[user_id] = [
                    msg for msg in user_messages[user_id]
                    if current_time - msg['timestamp'] < MESSAGE_LIFETIME
                ]

async def add_message_to_history(user_id: int, role: str, content: str):
    async with user_processing_locks[user_id]:
        if user_id not in user_messages:
            user_messages[user_id] = []
        user_messages[user_id].append({
            'role': role,
            'content': content,
            'timestamp': datetime.datetime.now()
        })

# --- Silence Mode Management ---
async def save_silence_state_to_file():
    logger.debug("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ –º–æ–ª—á–∞–Ω–∏—è (TG) –≤ —Ñ–∞–π–ª...")
    data_to_save = {str(chat_id): True for chat_id, is_silent in chat_silence_state.items() if is_silent}
    try:
        def _save():
            with open(SILENCE_STATE_FILE, "w", encoding="utf-8") as f:
                json.dump(data_to_save, f, indent=4)
        await asyncio.to_thread(_save)
        logger.info(f"–°–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ –º–æ–ª—á–∞–Ω–∏—è (TG) —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {SILENCE_STATE_FILE}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ –º–æ–ª—á–∞–Ω–∏—è (TG): {e}", exc_info=True)

async def load_silence_state_from_file():
    global chat_silence_state
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ –º–æ–ª—á–∞–Ω–∏—è (TG) –∏–∑ —Ñ–∞–π–ª–∞...")
    try:
        def _load():
            if not os.path.exists(SILENCE_STATE_FILE):
                logger.info(f"–§–∞–π–ª {SILENCE_STATE_FILE} (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.")
                return None
            with open(SILENCE_STATE_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        
        loaded_data = await asyncio.to_thread(_load)
        if not loaded_data:
            return

        restored_count = 0
        for chat_id_str, should_be_silent in loaded_data.items():
            try:
                chat_id = int(chat_id_str)
                if should_be_silent: 
                    chat_silence_state[chat_id] = True
                    logger.info(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π —Ä–µ–∂–∏–º –º–æ–ª—á–∞–Ω–∏—è –¥–ª—è chat_id={chat_id} (TG)")
                    restored_count += 1
            except (ValueError, KeyError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø–∏—Å–∏ (TG) –¥–ª—è chat_id_str='{chat_id_str}': {e}", exc_info=True)
        
        if restored_count > 0:
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {restored_count} —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –º–æ–ª—á–∞–Ω–∏—è (TG).")
        else:
            logger.info("–ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –º–æ–ª—á–∞–Ω–∏—è –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    except FileNotFoundError:
        logger.info(f"–§–∞–π–ª {SILENCE_STATE_FILE} (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å–∫ —Å —á–∏—Å—Ç—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –º–æ–ª—á–∞–Ω–∏—è.")
    except json.JSONDecodeError:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –∏–∑ —Ñ–∞–π–ª–∞ {SILENCE_STATE_FILE} (TG). –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω.")
    except Exception as e:
        logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ –º–æ–ª—á–∞–Ω–∏—è (TG): {e}", exc_info=True)

async def is_chat_silent(chat_id: int) -> bool:
    return chat_silence_state.get(chat_id, False)

async def set_chat_silence_permanently(chat_id: int, silent: bool):
    log_prefix = f"set_chat_silence_permanently(chat:{chat_id}, silent:{silent}):"
    current_state = chat_silence_state.get(chat_id, False)
    if current_state == silent:
        logger.debug(f"{log_prefix} –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ –º–æ–ª—á–∞–Ω–∏—è –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ({silent}).")
        return

    if silent:
        chat_silence_state[chat_id] = True
        logger.info(f"{log_prefix} –í–∫–ª—é—á–µ–Ω –ü–û–°–¢–û–Ø–ù–ù–´–ô —Ä–µ–∂–∏–º –º–æ–ª—á–∞–Ω–∏—è.")
    else: 
        if chat_id in chat_silence_state:
            del chat_silence_state[chat_id]
            logger.info(f"{log_prefix} –ü–û–°–¢–û–Ø–ù–ù–´–ô —Ä–µ–∂–∏–º –º–æ–ª—á–∞–Ω–∏—è —Å–Ω—è—Ç.")
        else:
            logger.debug(f"{log_prefix} –ü–æ–ø—ã—Ç–∫–∞ —Å–Ω—è—Ç—å –º–æ–ª—á–∞–Ω–∏–µ, –Ω–æ —á–∞—Ç –Ω–µ –±—ã–ª –≤ —Å–ø–∏—Å–∫–µ.")
    await save_silence_state_to_file()

# --- Message Buffering ---
async def schedule_buffered_processing(user_id: int, chat_id: int, business_connection_id: Optional[str]):
    log_prefix = f"schedule_buffered_processing(user:{user_id}, chat:{chat_id}):"
    current_task = asyncio.current_task()
    try:
        logger.debug(f"{log_prefix} –û–∂–∏–¥–∞–Ω–∏–µ {MESSAGE_BUFFER_SECONDS} —Å–µ–∫—É–Ω–¥...")
        await asyncio.sleep(MESSAGE_BUFFER_SECONDS)

        task_in_dict = user_message_timers.get(user_id)
        if task_in_dict is not current_task:
            logger.info(f"{log_prefix} –¢–∞–π–º–µ—Ä —Å—Ä–∞–±–æ—Ç–∞–ª, –Ω–æ –æ–Ω —É—Å—Ç–∞—Ä–µ–ª. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞.")
            return

        if user_id in user_message_timers: # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
             del user_message_timers[user_id]
        logger.debug(f"{log_prefix} –¢–∞–π–º–µ—Ä —Å—Ä–∞–±–æ—Ç–∞–ª –∏ —É–¥–∞–ª–µ–Ω. –í—ã–∑–æ–≤ process_buffered_messages.")
        asyncio.create_task(process_buffered_messages(user_id, chat_id, business_connection_id))

    except asyncio.CancelledError:
        logger.info(f"{log_prefix} –¢–∞–π–º–µ—Ä –æ—Ç–º–µ–Ω–µ–Ω.")
    except Exception as e:
        logger.error(f"{log_prefix} –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ —Ç–∞–π–º–µ—Ä–∞: {str(e)}", exc_info=True)
        if user_id in user_message_timers and user_message_timers.get(user_id) is current_task:
            del user_message_timers[user_id]

async def process_buffered_messages(user_id: int, chat_id: int, business_connection_id: Optional[str]):
    log_prefix = f"process_buffered_messages(user:{user_id}, chat:{chat_id}):"
    async with user_processing_locks[user_id]: 
        logger.debug(f"{log_prefix} –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è user_id={user_id} –ø–æ–ª—É—á–µ–Ω–∞.")
        messages_to_process = pending_messages.pop(user_id, [])
        
        if user_id in user_message_timers: 
            logger.warning(f"{log_prefix} –¢–∞–π–º–µ—Ä –¥–ª—è user_id={user_id} –≤—Å–µ –µ—â–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª! –û—Ç–º–µ–Ω—è–µ–º –∏ —É–¥–∞–ª—è–µ–º.")
            timer_to_cancel = user_message_timers.pop(user_id)
            if not timer_to_cancel.done():
                try: timer_to_cancel.cancel()
                except Exception as e_inner_cancel: logger.debug(f"{log_prefix} –û—à–∏–±–∫–∞ –æ—Ç–º–µ–Ω—ã —Ç–∞–π–º–µ—Ä–∞: {e_inner_cancel}")

        if not messages_to_process:
            logger.info(f"{log_prefix} –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –±—É—Ñ–µ—Ä–µ –¥–ª—è user_id={user_id}.")
            return

        combined_input = "\n".join(messages_to_process)
        num_messages = len(messages_to_process)
        logger.info(f'{log_prefix} –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è user_id={user_id} ({num_messages} —Å–æ–æ–±—â.): "{combined_input[:200]}..."')
        
        try:
            action_params = {"chat_id": chat_id, "action": ChatAction.TYPING}
            if business_connection_id: action_params["business_connection_id"] = business_connection_id
            await bot.send_chat_action(**action_params)
            logger.debug(f"{log_prefix} –û—Ç–ø—Ä–∞–≤–ª–µ–Ω —Å—Ç–∞—Ç—É—Å 'typing'.")

            response_text = await chat_with_assistant(user_id, combined_input)
            
            message_params = {"chat_id": chat_id, "text": response_text}
            if business_connection_id: message_params["business_connection_id"] = business_connection_id
            await bot.send_message(**message_params)
            logger.info(f"{log_prefix} –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª—è user_id={user_id}.")
        except Exception as e:
            logger.error(f"{log_prefix} –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è user_id={user_id}: {e}", exc_info=True)
            try:
                error_msg_params = {"chat_id": chat_id, "text": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."}
                if business_connection_id: error_msg_params["business_connection_id"] = business_connection_id
                await bot.send_message(**error_msg_params)
            except Exception as send_err_e: logger.error(f"{log_prefix} –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ user_id={user_id}: {send_err_e}")
        finally:
            logger.debug(f"{log_prefix} –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è user_id={user_id} –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞.")

# --- OpenAI Assistant Interaction ---
async def chat_with_assistant(user_id: int, user_input: str) -> str:
    log_prefix = f"chat_with_assistant(user:{user_id}):"
    logger.info(f"{log_prefix} –ó–∞–ø—Ä–æ—Å: {user_input[:100]}...")

    thread_id = await get_or_create_thread(user_id)
    if not thread_id:
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ (–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–ª–∏ –ø–æ–ª—É—á–∏—Ç—å —Ç—Ä–µ–¥ OpenAI)."

    context = ""
    if USE_VECTOR_STORE and vector_collection:
        try: context = await get_relevant_context_telegram(user_input, k=RELEVANT_CONTEXT_COUNT)
        except Exception as e_ctx: logger.error(f"{log_prefix} –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e_ctx}", exc_info=True)

    full_prompt = user_input
    if context:
        full_prompt = (
            f"–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n"
            f"--- –ù–ê–ß–ê–õ–û –ö–û–ù–¢–ï–ö–°–¢–ê ---\n{context}\n--- –ö–û–ù–ï–¶ –ö–û–ù–¢–ï–ö–°–¢–ê ---\n\n"
            f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_input}"
        )
        logger.info(f"{log_prefix} –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω –∫ –∑–∞–ø—Ä–æ—Å—É.")
    else:
        logger.info(f"{log_prefix} –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω–∞.")

    await add_message_to_history(user_id, "user", user_input) 

    try:
        logger.debug(f"{log_prefix} –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö runs –¥–ª—è —Ç—Ä–µ–¥–∞ {thread_id}...")
        active_runs_response = await openai_client.beta.threads.runs.list(thread_id=thread_id)
        active_runs_to_cancel = [run for run in active_runs_response.data if run.status in ['queued', 'in_progress', 'requires_action']]
        if active_runs_to_cancel:
            logger.warning(f"{log_prefix} –ù–∞–π–¥–µ–Ω–æ {len(active_runs_to_cancel)} –∞–∫—Ç–∏–≤–Ω—ã—Ö/–æ–∂–∏–¥–∞—é—â–∏—Ö runs. –û—Ç–º–µ–Ω—è–µ–º...")
            for run_to_cancel in active_runs_to_cancel:
                try:
                    await openai_client.beta.threads.runs.cancel(thread_id=thread_id, run_id=run_to_cancel.id)
                    logger.info(f"{log_prefix} –û—Ç–º–µ–Ω–µ–Ω run {run_to_cancel.id}")
                except Exception as cancel_error: logger.warning(f"{log_prefix} –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–º–µ–Ω–∏—Ç—å run {run_to_cancel.id}: {cancel_error}")
        
        await openai_client.beta.threads.messages.create(thread_id=thread_id, role="user", content=full_prompt)
        logger.info(f"{log_prefix} –°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ —Ç—Ä–µ–¥ {thread_id}")

        current_run = await openai_client.beta.threads.runs.create(thread_id=thread_id, assistant_id=ASSISTANT_ID)
        logger.info(f"{log_prefix} –ó–∞–ø—É—â–µ–Ω –Ω–æ–≤—ã–π run {current_run.id}")

        start_time = time.time()
        run_completed_successfully = False
        while time.time() - start_time < OPENAI_RUN_TIMEOUT_SECONDS:
            await asyncio.sleep(1.5) 
            run_status = await openai_client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=current_run.id)
            logger.debug(f"{log_prefix} –°—Ç–∞—Ç—É—Å run {current_run.id}: {run_status.status}")
            if run_status.status == 'completed':
                logger.info(f"{log_prefix} Run {current_run.id} —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω.")
                run_completed_successfully = True
                break
            elif run_status.status in ['failed', 'cancelled', 'expired']:
                error_message_detail = f"Run {current_run.id} —Å—Ç–∞—Ç—É—Å '{run_status.status}'."
                last_error = getattr(run_status, 'last_error', None)
                if last_error: error_message_detail += f" –û—à–∏–±–∫–∞: {last_error.message} (–ö–æ–¥: {last_error.code})"
                logger.error(f"{log_prefix} {error_message_detail}")
                await log_context_telegram(user_id, user_input, context, f"–û–®–ò–ë–ö–ê OPENAI: {error_message_detail}")
                return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (—Å—Ç–∞—Ç—É—Å OpenAI)."
            elif run_status.status == 'requires_action':
                 logger.warning(f"{log_prefix} Run {current_run.id} —Ç—Ä–µ–±—É–µ—Ç –¥–µ–π—Å—Ç–≤–∏—è (Function Calling?).")
                 await openai_client.beta.threads.runs.cancel(thread_id=thread_id, run_id=current_run.id)
                 await log_context_telegram(user_id, user_input, context, "–û–®–ò–ë–ö–ê OPENAI: requires_action")
                 return "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (OpenAI requires_action)."
        
        if not run_completed_successfully: # –¢–∞–π–º–∞—É—Ç
            logger.warning(f"{log_prefix} –¢–∞–π–º–∞—É—Ç ({OPENAI_RUN_TIMEOUT_SECONDS}s) –¥–ª—è run {current_run.id}")
            try:
                await openai_client.beta.threads.runs.cancel(thread_id=thread_id, run_id=current_run.id)
                logger.info(f"{log_prefix} –û—Ç–º–µ–Ω–µ–Ω run {current_run.id} –∏–∑-–∑–∞ —Ç–∞–π–º–∞—É—Ç–∞.")
            except Exception as cancel_error: logger.warning(f"{log_prefix} –û—à–∏–±–∫–∞ –æ—Ç–º–µ–Ω—ã run {current_run.id} –ø–æ—Å–ª–µ —Ç–∞–π–º–∞—É—Ç–∞: {cancel_error}")
            await log_context_telegram(user_id, user_input, context, "–û–®–ò–ë–ö–ê OPENAI: –¢–∞–π–º–∞—É—Ç")
            return "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Ç–∞–π–º–∞—É—Ç OpenAI)."

        messages_response = await openai_client.beta.threads.messages.list(thread_id=thread_id, order="desc", limit=5)
        assistant_response_content = None
        for msg in messages_response.data:
            if msg.role == "assistant" and msg.run_id == current_run.id:
                if msg.content and msg.content[0].type == 'text': # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫
                    assistant_response_content = msg.content[0].text.value
                    logger.info(f"{log_prefix} –ü–æ–ª—É—á–µ–Ω —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç: {assistant_response_content[:100]}...")
                    break
        
        if assistant_response_content:
            await add_message_to_history(user_id, "assistant", assistant_response_content)
            await log_context_telegram(user_id, user_input, context, assistant_response_content)
            return assistant_response_content
        else:
            logger.warning(f"{log_prefix} –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –¥–ª—è run {current_run.id} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            await log_context_telegram(user_id, user_input, context, "–û–¢–í–ï–¢ –ê–°–°–ò–°–¢–ï–ù–¢–ê –ù–ï –ù–ê–ô–î–ï–ù –ò–õ–ò –ü–£–°–¢")
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."

    except openai.APIError as e: # –ë–æ–ª–µ–µ –æ–±—â–∞—è –æ—à–∏–±–∫–∞ API OpenAI
        logger.error(f"{log_prefix} –û—à–∏–±–∫–∞ OpenAI API: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ OpenAI: {str(e)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
    except Exception as e:
        logger.error(f"{log_prefix} –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        await log_context_telegram(user_id, user_input, context, f"–ù–ï–ü–†–ï–î–í–ò–î–ï–ù–ù–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞."

# --- Vector Store Management (ChromaDB) ---
async def get_relevant_context_telegram(query: str, k: int) -> str:
    if not vector_collection:
        logger.warning("–ó–∞–ø—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (TG), –Ω–æ vector_collection –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞.")
        return ""
    try:
        try:
            query_embedding_response = await openai_client.embeddings.create(
                 input=[query], model=OPENAI_EMBEDDING_MODEL, dimensions=OPENAI_EMBEDDING_DIMENSIONS
            )
            query_embedding = query_embedding_response.data[0].embedding
            logger.debug(f"–≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (TG) '{query[:50]}...' —Å–æ–∑–¥–∞–Ω.")
        except Exception as e_embed:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (TG): {e_embed}", exc_info=True)
            return ""

        def _query_chroma():
            return vector_collection.query(query_embeddings=[query_embedding], n_results=k, include=["documents", "metadatas"]) # –£–±—Ä–∞–ª–∏ distances –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
        results = await asyncio.to_thread(_query_chroma)
        logger.debug(f"–ü–æ–∏—Å–∫ –≤ ChromaDB (TG) –¥–ª—è '{query[:50]}...' –≤—ã–ø–æ–ª–Ω–µ–Ω.")

        if not results or not results.get("ids") or not results["ids"][0] or \
           not results.get("documents") or not results["documents"][0]:
            logger.info(f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è: '{query[:50]}...'")
            return ""

        documents = results["documents"][0]
        metadatas = results["metadatas"][0] if results.get("metadatas") and results["metadatas"][0] else [{}] * len(documents)
        context_pieces = []
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(documents)} –¥–æ–∫-–≤ (TG) –¥–ª—è '{query[:50]}...'. –¢–æ–ø {k}:")
        for i, doc_content in enumerate(documents):
            meta = metadatas[i] if i < len(metadatas) else {}
            source = meta.get('source', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫')
            logger.info(f"  #{i+1} (TG): –ò—Å—Ç–æ—á–Ω–∏–∫='{source}', –ö–æ–Ω—Ç–µ–Ω—Ç='{doc_content[:100]}...'")
            context_pieces.append(f"–ò–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ '{source}':\n{doc_content}")

        if not context_pieces: return ""
        return "\n\n---\n\n".join(context_pieces)
    except Exception as e:
        logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (TG): {e}", exc_info=True)
        return ""

async def update_vector_store_telegram(chat_id_to_notify: Optional[int] = None) -> Dict[str, Any]:
    logger.info("--- –ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (TG) ---")
    os.makedirs(VECTOR_DB_BASE_PATH, exist_ok=True)
    timestamp_dir_name = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f") + "_new_tg"
    new_db_subpath = timestamp_dir_name 
    new_db_full_path = os.path.join(VECTOR_DB_BASE_PATH, new_db_subpath)
    logger.info(f"–ù–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ë–î (TG): {new_db_full_path}")

    previous_active_full_path = _get_active_db_full_path_telegram() 

    try:
        os.makedirs(new_db_full_path, exist_ok=True)
    except Exception as e_mkdir:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é '{new_db_full_path}' (TG): {e_mkdir}.", exc_info=True)
        return {"success": False, "error": f"Failed to create temp dir: {e_mkdir}", "added_chunks": 0, "total_chunks": 0}

    temp_vector_collection: Optional[chromadb.api.models.Collection.Collection] = None
    try:
        def _init_temp_chroma():
            temp_chroma_client = chromadb.PersistentClient(path=new_db_full_path)
            return temp_chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)
        temp_vector_collection = await asyncio.to_thread(_init_temp_chroma)
        logger.info(f"–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è '{CHROMA_COLLECTION_NAME}' (TG) —Å–æ–∑–¥–∞–Ω–∞/–ø–æ–ª—É—á–µ–Ω–∞ –≤ '{new_db_full_path}'.")

        logger.info("–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Drive (TG)...")
        documents_data = await asyncio.to_thread(read_data_from_drive_sync)
        if not documents_data:
            logger.warning("–î–æ–∫—É–º–µ–Ω—Ç—ã –≤ Google Drive (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ.")
            if os.path.exists(new_db_full_path):
                await asyncio.to_thread(shutil.rmtree, new_db_full_path)
            return {"success": False, "error": "No documents in Google Drive", "added_chunks": 0, "total_chunks": 0}
        
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(documents_data)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ Google Drive (TG).")
        all_texts, all_metadatas = [], []
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[("#", "h1"), ("##", "h2"), ("###", "h3")])
        MD_SECTION_MAX_LEN = 2000 

        for doc_info in documents_data:
            doc_name, doc_content_str = doc_info['name'], doc_info['content']
            if not doc_content_str or not doc_content_str.strip():
                logger.warning(f"–î–æ–∫—É–º–µ–Ω—Ç '{doc_name}' (TG) –ø—É—Å—Ç.")
                continue
            
            enhanced_doc_content = f"–î–æ–∫—É–º–µ–Ω—Ç: {doc_name}\n\n{doc_content_str}" # –ò–°–ü–†–ê–í–õ–ï–ù–û \n
            chunk_idx = 0
            is_md = doc_name.lower().endswith(('.md', '.markdown'))
            try:
                target_splits = markdown_splitter.split_text(enhanced_doc_content) if is_md else text_splitter.split_text(enhanced_doc_content)
                
                for item_split in target_splits:
                    page_content = item_split.page_content if isinstance(item_split, Document) else item_split
                    current_metadata = item_split.metadata if isinstance(item_split, Document) else {}
                    
                    if is_md and len(page_content) > MD_SECTION_MAX_LEN and not isinstance(item_split, Document): # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è MD –±–µ–∑ Document
                        sub_chunks = text_splitter.split_text(page_content)
                        for sub_chunk_text in sub_chunks:
                            all_texts.append(sub_chunk_text)
                            all_metadatas.append({"source": doc_name, **current_metadata, "type": "md_split", "chunk": chunk_idx})
                            chunk_idx += 1
                    elif isinstance(item_split, Document) and len(page_content) > MD_SECTION_MAX_LEN : # –ï—Å–ª–∏ —ç—Ç–æ Document –∏ –¥–ª–∏–Ω–Ω—ã–π
                        sub_chunks = text_splitter.split_text(page_content)
                        for sub_chunk_text in sub_chunks:
                            all_texts.append(sub_chunk_text)
                            all_metadatas.append({"source": doc_name, **current_metadata, "type": "doc_split", "chunk": chunk_idx}) # type: doc_split
                            chunk_idx +=1
                    else:
                        all_texts.append(page_content)
                        all_metadatas.append({"source": doc_name, **current_metadata, "type": "md" if is_md else "text", "chunk": chunk_idx})
                        chunk_idx += 1
                logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç '{doc_name}' (TG) —Ä–∞–∑–±–∏—Ç –Ω–∞ {chunk_idx} —á–∞–Ω–∫–æ–≤.")
            except Exception as e_split:
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è '{doc_name}' (TG): {e_split}", exc_info=True)
                try: # Fallback
                    chunks = text_splitter.split_text(enhanced_doc_content)
                    chunk_idx_fb = 0 
                    for chunk_text in chunks:
                        all_texts.append(chunk_text)
                        all_metadatas.append({"source": doc_name, "type": "text_fallback", "chunk": chunk_idx_fb})
                        chunk_idx_fb += 1
                    logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç '{doc_name}' (TG) (fallback) —Ä–∞–∑–±–∏—Ç –Ω–∞ {chunk_idx_fb} —á–∞–Ω–∫–æ–≤.")
                except Exception as e_fallback: logger.error(f"–û—à–∏–±–∫–∞ fallback-—Ä–∞–∑–±–∏–µ–Ω–∏—è '{doc_name}' (TG): {e_fallback}", exc_info=True)
        
        if not all_texts:
            logger.warning("–ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –±–∞–∑—É (TG).")
            if os.path.exists(new_db_full_path):
                await asyncio.to_thread(shutil.rmtree, new_db_full_path)
            return {"success": False, "error": "No text data to add", "added_chunks": 0, "total_chunks": 0}

        logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(all_texts)} —á–∞–Ω–∫–æ–≤ (TG)...")
        embeddings_response = await openai_client.embeddings.create(
            input=all_texts, model=OPENAI_EMBEDDING_MODEL, dimensions=OPENAI_EMBEDDING_DIMENSIONS
        )
        all_embeddings = [item.embedding for item in embeddings_response.data]
        all_ids = [f"{meta['source']}_{meta.get('type','unk')}_{meta['chunk']}_{i}" for i, meta in enumerate(all_metadatas)] # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ ID

        if temp_vector_collection:
            def _add_to_chroma():
                temp_vector_collection.add(ids=all_ids, embeddings=all_embeddings, metadatas=all_metadatas, documents=all_texts)
                return temp_vector_collection.count()
            final_total = await asyncio.to_thread(_add_to_chroma)
            final_added = len(all_ids)
            logger.info(f"–£—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {final_added} —á–∞–Ω–∫–æ–≤ (TG). –í—Å–µ–≥–æ: {final_total}.")
        else: # –ù–µ –¥–æ–ª–∂–Ω–æ —Å–ª—É—á–∏—Ç—å—Å—è
            logger.error("temp_vector_collection (TG) –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
            if os.path.exists(new_db_full_path):
                await asyncio.to_thread(shutil.rmtree, new_db_full_path)
            return {"success": False, "error": "temp_vector_collection is None", "added_chunks": 0, "total_chunks": 0}

        active_db_info_filepath = os.path.join(VECTOR_DB_BASE_PATH, ACTIVE_DB_INFO_FILE)
        with open(active_db_info_filepath, "w", encoding="utf-8") as f: f.write(new_db_full_path) # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ü–û–õ–ù–´–ô –ø—É—Ç—å
        logger.info(f"–ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –Ω–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ–π –±–∞–∑–µ (TG) '{new_db_full_path}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ '{active_db_info_filepath}'.")

        await _initialize_active_vector_collection_telegram()
        if not vector_collection:
             logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (TG): –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å vector_collection!")
             return {"success": False, "error": "Failed to reload global vector_collection", "added_chunks": final_added, "total_chunks": final_total}
        
        if previous_active_full_path and previous_active_full_path != new_db_full_path and os.path.exists(previous_active_full_path):
            try:
                await asyncio.to_thread(shutil.rmtree, previous_active_full_path)
                logger.info(f"–£–¥–∞–ª–µ–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ë–î (TG): '{previous_active_full_path}'")
            except Exception as e_rm_old: logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â—É—é –ë–î (TG) '{previous_active_full_path}': {e_rm_old}", exc_info=True)
        
        logger.info("--- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (TG) —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ ---")
        return {"success": True, "added_chunks": final_added, "total_chunks": final_total, "new_active_path": new_db_full_path}

    except openai.APIError as e_openai:
         logger.error(f"OpenAI API –æ—à–∏–±–∫–∞ (TG): {e_openai}", exc_info=True)
         if os.path.exists(new_db_full_path):
             await asyncio.to_thread(shutil.rmtree, new_db_full_path)
         return {"success": False, "error": f"OpenAI API error: {e_openai}", "added_chunks": 0, "total_chunks": 0}
    except Exception as e_main_update:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–ó (TG): {e_main_update}", exc_info=True)
        if os.path.exists(new_db_full_path):
            await asyncio.to_thread(shutil.rmtree, new_db_full_path)
        return {"success": False, "error": f"Critical update error: {e_main_update}", "added_chunks": 0, "total_chunks": 0}

# --- Telegram Command Handlers ---
@router.message(Command("start"))
async def start_command(message: aiogram_types.Message):
    await message.answer("üëã –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –û–±–Ω–æ–≤–ª—è—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...")
    asyncio.create_task(run_update_and_notify_telegram(message.chat.id))

async def run_update_and_notify_telegram(chat_id: int):
    logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–ó (TG) –¥–ª—è —á–∞—Ç–∞ {chat_id}...")
    update_result = await update_vector_store_telegram(chat_id_to_notify=chat_id)
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    user_message = f"üîî –û—Ç—á–µ—Ç –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ë–ó ({current_time}):\n"
    if update_result.get("success"):
        user_message += (f"‚úÖ –£—Å–ø–µ—à–Ω–æ!\n‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ: {update_result.get('added_chunks', 'N/A')}\n"
                         f"üìä –í—Å–µ–≥–æ: {update_result.get('total_chunks', 'N/A')}\n")
        if update_result.get("new_active_path"): user_message += f"üìÅ –ü—É—Ç—å: {os.path.basename(update_result['new_active_path'])}" # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è –ø–∞–ø–∫–∏
    else:
        user_message += f"‚ùå –û—à–∏–±–∫–∞: {update_result.get('error', 'N/A')}"
    
    try: await bot.send_message(chat_id, user_message)
    except Exception as e: logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {chat_id} (TG): {e}")

    if ADMIN_USER_ID and chat_id != ADMIN_USER_ID: # –î—É–±–ª–∏—Ä—É–µ–º –∞–¥–º–∏–Ω—É, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –æ–Ω –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–ª
        try: await bot.send_message(ADMIN_USER_ID, "[–ê–≤—Ç–æ] " + user_message)
        except Exception as e: logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∞–¥–º–∏–Ω—É (TG): {e}")

@router.message(Command("update"))
async def update_knowledge_command(message: aiogram_types.Message):
    if message.from_user.id != ADMIN_USER_ID:
        await message.answer("‚ùå –ù–µ—Ç –ø—Ä–∞–≤!")
        return
    await message.answer("üîÑ –û–±–Ω–æ–≤–ª—è—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (TG)...")
    asyncio.create_task(run_update_and_notify_telegram(ADMIN_USER_ID))

@router.message(Command("reset"))
async def reset_conversation_command(message: aiogram_types.Message):
    user_id = message.from_user.id
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /reset –æ—Ç user_id={user_id} (TG).")
    
    async with user_processing_locks[user_id]:
        if user_id in pending_messages: del pending_messages[user_id]
        if user_id in user_message_timers:
            timer = user_message_timers.pop(user_id)
            if not timer.done(): timer.cancel()
        
        thread_id = user_threads.pop(user_id, None)
        if thread_id: logger.info(f"–¢—Ä–µ–¥ {thread_id} –¥–ª—è user_id={user_id} —É–¥–∞–ª–µ–Ω –∏–∑ –ø–∞–º—è—Ç–∏ (TG).")
        if user_id in user_messages: del user_messages[user_id]
        
    await message.answer("üîÑ –î–∏–∞–ª–æ–≥ —Å–±—Ä–æ—à–µ–Ω!")

@router.message(Command("reset_all"))
async def reset_all_command(message: aiogram_types.Message):
    if message.from_user.id != ADMIN_USER_ID:
        await message.answer("‚ùå –ù–µ—Ç –ø—Ä–∞–≤!")
        return
    logger.warning(f"–ê–¥–º–∏–Ω {ADMIN_USER_ID} –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–ª –ü–û–õ–ù–´–ô –°–ë–†–û–° (TG)!")
    # ... (–ª–æ–≥–∏–∫–∞ –æ—Ç–º–µ–Ω—ã —Ç–∞–π–º–µ—Ä–æ–≤, –æ—á–∏—Å—Ç–∫–∏ —Å–ª–æ–≤–∞—Ä–µ–π user_threads, user_messages, pending_messages) ...
    timers_cancelled = 0
    for timer_task in list(user_message_timers.values()): # Iterate over a copy
        if not timer_task.done():
            timer_task.cancel()
            timers_cancelled +=1
    user_message_timers.clear()
    pending_messages_cleared = len(pending_messages)
    pending_messages.clear()
    threads_cleared = len(user_threads)
    user_threads.clear()
    user_messages_cleared = len(user_messages)
    user_messages.clear()

    await message.answer(f"üîÑ –í–°–ï –î–ò–ê–õ–û–ì–ò –°–ë–†–û–®–ï–ù–´ (TG).\n"
                         f"- –¢–∞–π–º–µ—Ä–æ–≤ –æ—Ç–º–µ–Ω–µ–Ω–æ: {timers_cancelled}\n"
                         f"- –ë—É—Ñ–µ—Ä–æ–≤ –æ—á–∏—â–µ–Ω–æ: {pending_messages_cleared}\n"
                         f"- –¢—Ä–µ–¥–æ–≤ (–ø–∞–º—è—Ç—å): {threads_cleared}\n"
                         f"- –ò—Å—Ç–æ—Ä–∏–π (–ø–∞–º—è—Ç—å): {user_messages_cleared}")

@router.message(Command("speak"))
async def speak_command(message: aiogram_types.Message):
    user_id = message.from_user.id
    chat_id = message.chat.id
    is_manager_or_admin = user_id == ADMIN_USER_ID or user_id in MANAGER_USER_IDS

    if not is_manager_or_admin:
        logger.debug(f"User {user_id} (–Ω–µ –º–µ–Ω–µ–¥–∂–µ—Ä) –ø–æ–ø—ã—Ç–∞–ª—Å—è /speak –≤ —á–∞—Ç–µ {chat_id}.")
        return

    if await is_chat_silent(chat_id):
        await set_chat_silence_permanently(chat_id, False)
        await message.answer("ü§ñ –†–µ–∂–∏–º –º–æ–ª—á–∞–Ω–∏—è —Å–Ω—è—Ç. –ë–æ—Ç —Å–Ω–æ–≤–∞ –∞–∫—Ç–∏–≤–µ–Ω.")
        logger.info(f"–ú–µ–Ω–µ–¥–∂–µ—Ä/–∞–¥–º–∏–Ω {user_id} —Å–Ω—è–ª –º–æ–ª—á–∞–Ω–∏–µ –¥–ª—è —á–∞—Ç–∞ {chat_id} (TG).")
    else:
        await message.answer("‚ÑπÔ∏è –ë–æ—Ç —É–∂–µ –±—ã–ª –∞–∫—Ç–∏–≤–µ–Ω.")

@router.message(Command("check_db"))
async def check_database_command(message: aiogram_types.Message):
    await message.answer("üîç –ü—Ä–æ–≤–µ—Ä—è—é –∞–∫—Ç–∏–≤–Ω—É—é –±–∞–∑—É –≤–µ–∫—Ç–æ—Ä–æ–≤ (TG)...")
    active_db_full_path = _get_active_db_full_path_telegram()

    if not active_db_full_path:
        await message.answer("‚ùå –ê–∫—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (TG) –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞.")
        return

    report = [f"‚úÖ –ê–∫—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å –ë–î (TG): {active_db_full_path}"]
    try:
        files = await asyncio.to_thread(os.listdir, active_db_full_path)
        report.append(f"üìÑ –§–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {', '.join(files) if files else '–ü—É—Å—Ç–æ'}")
    except Exception as e: report.append(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}")

    if vector_collection:
        try:
            count = await asyncio.to_thread(vector_collection.count)
            report.append(f"üìä –ö–æ–ª-–≤–æ –∑–∞–ø–∏—Å–µ–π (–≥–ª–æ–±.): {count}")
        except Exception as e: report.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –≥–ª–æ–±. –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
    else:
        report.append("‚ÑπÔ∏è –ì–ª–æ–±–∞–ª—å–Ω–∞—è vector_collection –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞. –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä—è–º–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...")
        try:
            def _direct_count():
                client = chromadb.PersistentClient(path=active_db_full_path)
                return client.get_collection(CHROMA_COLLECTION_NAME).count()
            count_direct = await asyncio.to_thread(_direct_count)
            report.append(f"üìä –ö–æ–ª-–≤–æ –∑–∞–ø–∏—Å–µ–π (–ø—Ä—è–º–æ–µ): {count_direct}")
        except Exception as e: report.append(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞: {e}")
    
    await message.answer("\n".join(report))

# --- Message Handlers ---
# –í–∞–∂–Ω–æ: —Ö–µ–Ω–¥–ª–µ—Ä—ã –∫–æ–º–∞–Ω–¥ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ router –î–û –æ–±—â–∏—Ö —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π,
# —á—Ç–æ–±—ã –æ–Ω–∏ –∏–º–µ–ª–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç. Aiogram –æ–±—ã—á–Ω–æ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ Command —Ñ–∏–ª—å—Ç—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è.

@dp.business_message() 
async def handle_business_message(message: aiogram_types.Message):
    user_id = message.from_user.id 
    chat_id = message.chat.id 
    message_text = message.text or ""
    business_connection_id = message.business_connection_id
    log_prefix = f"handle_business_message(user:{user_id}, chat:{chat_id}, biz_conn:{business_connection_id}):"

    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ: –µ—Å–ª–∏ —ç—Ç–æ dp.business_message, —Ç–æ –ø–∏—à–µ—Ç –ö–õ–ò–ï–ù–¢ –ë–ò–ó–ù–ï–°–£.
    # –û—Ç–≤–µ—Ç—ã –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —á–µ—Ä–µ–∑ Telegram Business API –º–æ–≥—É—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∫–∞–∫-—Ç–æ –∏–Ω–∞—á–µ
    # –∏–ª–∏ –∏–º–µ—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, message.outgoing == True).
    # –¢–µ–∫—É—â–∞—è –ª–æ–≥–∏–∫–∞ –≤–∫–ª—é—á–µ–Ω–∏—è –º–æ–ª—á–∞–Ω–∏—è –ø–æ –æ—Ç–≤–µ—Ç—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∑–¥–µ—Å—å –ù–ï –°–†–ê–ë–û–¢–ê–ï–¢,
    # –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –º–µ–Ω–µ–¥–∂–µ—Ä –Ω–µ –ø–∏—à–µ—Ç —Å–∞–º —Å–µ–±–µ –≤ –±–∏–∑–Ω–µ—Å-—á–∞—Ç —Å –±–æ—Ç–æ–º (—á—Ç–æ –Ω–µ—Ç–∏–ø–∏—á–Ω–æ).
    # –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ–Ω–∞, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç —è—Å–Ω–∞ –º–µ—Ö–∞–Ω–∏–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤ –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤.

    if await is_chat_silent(chat_id):
        logger.info(f"{log_prefix} –ë–æ—Ç –≤ —Ä–µ–∂–∏–º–µ –º–æ–ª—á–∞–Ω–∏—è. –°–æ–æ–±—â–µ–Ω–∏–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.")
        return
    if not message_text.strip():
        logger.info(f"{log_prefix} –ü—É—Å—Ç–æ–µ –±–∏–∑–Ω–µ—Å-—Å–æ–æ–±—â–µ–Ω–∏–µ. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º.")
        return

    pending_messages.setdefault(user_id, []).append(message_text)
    logger.debug(f"{log_prefix} –ë–∏–∑–Ω–µ—Å-—Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –±—É—Ñ–µ—Ä.")
    if user_id in user_message_timers:
        timer = user_message_timers.pop(user_id)
        if not timer.done(): timer.cancel()
    
    new_timer = asyncio.create_task(schedule_buffered_processing(user_id, chat_id, business_connection_id))
    user_message_timers[user_id] = new_timer

@router.message(F.business_connection_id.is_(None)) 
async def handle_regular_message(message: aiogram_types.Message):
    user_id = message.from_user.id
    chat_id = message.chat.id
    message_text = message.text or ""
    log_prefix = f"handle_regular_message(user:{user_id}, chat:{chat_id}):"

    is_sender_admin = user_id == ADMIN_USER_ID
    is_sender_manager = user_id in MANAGER_USER_IDS
    
    # –ï—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä (–Ω–µ –∞–¥–º–∏–Ω) –ø–∏—à–µ—Ç –±–æ—Ç—É –Ω–∞–ø—Ä—è–º—É—é (–Ω–µ –∫–æ–º–∞–Ω–¥–∞)
    if is_sender_manager and not is_sender_admin and not message_text.startswith('/'):
        if not await is_chat_silent(chat_id):
            logger.info(f"{log_prefix} –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞ {user_id}. –í–∫–ª—é—á–∞–µ–º –ø–æ—Å—Ç. –º–æ–ª—á–∞–Ω–∏–µ –¥–ª—è chat_id={chat_id}.")
            await set_chat_silence_permanently(chat_id, True)
        else:
            logger.info(f"{log_prefix} –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞ {user_id}, –Ω–æ –±–æ—Ç —É–∂–µ –º–æ–ª—á–∏—Ç –¥–ª—è chat_id={chat_id}.")
        return 

    if await is_chat_silent(chat_id):
        logger.info(f"{log_prefix} –ë–æ—Ç –≤ —Ä–µ–∂–∏–º–µ –º–æ–ª—á–∞–Ω–∏—è. –°–æ–æ–±—â–µ–Ω–∏–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.")
        return
    if not message_text.strip():
        logger.info(f"{log_prefix} –ü—É—Å—Ç–æ–µ –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º.")
        return

    pending_messages.setdefault(user_id, []).append(message_text)
    logger.debug(f"{log_prefix} –û–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –±—É—Ñ–µ—Ä.")
    if user_id in user_message_timers:
        timer = user_message_timers.pop(user_id)
        if not timer.done(): timer.cancel()
    
    new_timer = asyncio.create_task(schedule_buffered_processing(user_id, chat_id, None))
    user_message_timers[user_id] = new_timer

# --- Background Tasks & Utility ---
async def log_context_telegram(user_id: int, query: str, context: str, response_text: Optional[str] = None):
    try:
        ts = datetime.datetime.now()
        log_filename = os.path.join(LOGS_DIR, f"context_tg_{user_id}_{ts.strftime('%Y%m%d_%H%M%S_%f')}.log")
        async def _write():
            with open(log_filename, "w", encoding="utf-8") as f:
                f.write(f"Timestamp: {ts.isoformat()}\nUser ID: {user_id}\n"
                        f"--- User Query ---\n{query}\n"
                        f"--- Retrieved Context ---\n{context or '–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.'}\n")
                if response_text: f.write(f"--- Assistant Response ---\n{response_text}\n")
        await asyncio.to_thread(_write)
        logger.debug(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç (TG) –¥–ª—è user_id {user_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {log_filename}")
    except Exception as e: logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (TG) –¥–ª—è user_id={user_id}: {e}", exc_info=True)

async def cleanup_old_context_logs_telegram():
    logger.info("–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (TG)...")
    count = 0
    try:
        cutoff = time.time() - LOG_RETENTION_SECONDS
        log_files = await asyncio.to_thread(glob.glob, os.path.join(LOGS_DIR, "context_tg_*.log"))
        for filename in log_files:
            try:
                if await asyncio.to_thread(os.path.getmtime, filename) < cutoff:
                    await asyncio.to_thread(os.remove, filename)
                    count += 1
            except FileNotFoundError: continue
            except Exception as e: logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ª–æ–≥–∞ {filename} (TG): {e}")
        logger.info(f"–û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤ (TG): —É–¥–∞–ª–µ–Ω–æ {count} —Ñ–∞–π–ª–æ–≤." if count > 0 else "–£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –ª–æ–≥–∏ (TG) –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
    except Exception as e: logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ª–æ–≥–æ–≤ (TG): {e}", exc_info=True)

async def daily_database_update_telegram():
    logger.info("–ó–∞–¥–∞—á–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î (TG) –∑–∞–ø—É—â–µ–Ω–∞.")
    while True:
        try:
            now = datetime.datetime.now()
            target = now.replace(hour=3, minute=0, second=0, microsecond=0)
            if now >= target: target += datetime.timedelta(days=1)
            sleep_duration = (target - now).total_seconds()
            logger.info(f"–ï–∂–µ–¥–Ω–µ–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î (TG) –≤ {target:%Y-%m-%d %H:%M:%S}. –û–∂–∏–¥–∞–Ω–∏–µ {sleep_duration:.0f}—Å...")
            await asyncio.sleep(sleep_duration)
            
            logger.info("–ï–∂–µ–¥–Ω–µ–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î (TG): –ó–∞–ø—É—Å–∫...")
            update_result = await update_vector_store_telegram()
            logger.info("–ï–∂–µ–¥–Ω–µ–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î (TG): –ó–∞–≤–µ—Ä—à–µ–Ω–æ.")
            
            if ADMIN_USER_ID:
                msg = f"üîî –ï–∂–µ–¥–Ω–µ–≤–Ω–æ–µ –∞–≤—Ç–æ-–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–ó (TG):\n"
                if update_result.get("success"):
                    msg += (f"‚úÖ –£—Å–ø–µ—à–Ω–æ!\n‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ: {update_result.get('added_chunks', 'N/A')}\n"
                            f"üìä –í—Å–µ–≥–æ: {update_result.get('total_chunks', 'N/A')}\n")
                    if update_result.get("new_active_path"): msg += f"üìÅ –ü—É—Ç—å: {os.path.basename(update_result['new_active_path'])}"
                else: msg += f"‚ùå –û—à–∏–±–∫–∞: {update_result.get('error', 'N/A')}"
                try: await bot.send_message(ADMIN_USER_ID, msg)
                except Exception as e: logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á–µ—Ç–∞ –∞–¥–º–∏–Ω—É (TG): {e}")
            await asyncio.sleep(60)
        except asyncio.CancelledError:
             logger.info("–ó–∞–¥–∞—á–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î (TG) –æ—Ç–º–µ–Ω–µ–Ω–∞.")
             break
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î (TG): {e}", exc_info=True)
            await asyncio.sleep(3600)

async def periodic_cleanup_telegram():
    logger.info("–ó–∞–¥–∞—á–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ (TG) –∑–∞–ø—É—â–µ–Ω–∞.")
    while True:
        try:
            await cleanup_old_context_logs_telegram()
            await cleanup_old_messages_in_memory()
            logger.info("–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ (TG) –≤—ã–ø–æ–ª–Ω–µ–Ω–∞.")
            await asyncio.sleep(3600) 
        except asyncio.CancelledError:
             logger.info("–ó–∞–¥–∞—á–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ (TG) –æ—Ç–º–µ–Ω–µ–Ω–∞.")
             break
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏ (TG): {e}", exc_info=True)
            await asyncio.sleep(300)

# --- PID File Management and Signal Handling ---
PID_FILE_BASENAME = "telegram_bot"
def create_pid_file():
    pid = os.getpid()
    pid_file = f'{PID_FILE_BASENAME}.pid'; i = 1
    while os.path.exists(pid_file): i += 1; pid_file = f'{PID_FILE_BASENAME}_{i}.pid'
    try:
        with open(pid_file, 'w') as f: f.write(str(pid))
        logger.info(f"–°–æ–∑–¥–∞–Ω PID —Ñ–∞–π–ª: {pid_file} (PID: {pid})")
    except OSError as e: logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å PID —Ñ–∞–π–ª {pid_file}: {e}")

def remove_pid_files():
    pid_files = glob.glob(f'{PID_FILE_BASENAME}*.pid')
    if not pid_files: return
    logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ PID —Ñ–∞–π–ª–æ–≤ (TG): {pid_files}...")
    for pf in pid_files:
        try: os.remove(pf); logger.info(f"–£–¥–∞–ª–µ–Ω {pf} (TG)")
        except OSError as e: logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {pf} (TG): {e}")

async def shutdown(signal_obj, loop):
    logger.warning(f"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signal_obj.name}, –Ω–∞—á–∏–Ω–∞—é –æ—Å—Ç–∞–Ω–æ–≤–∫—É...")
    tasks = [t for t in asyncio.all_tasks(loop) if t is not asyncio.current_task()]
    if tasks:
        logger.info(f"–û—Ç–º–µ–Ω—è—é {len(tasks)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á...")
        for task in tasks: task.cancel()
        await asyncio.gather(*tasks, return_exceptions=True)
        logger.info("–í—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –æ—Ç–º–µ–Ω–µ–Ω—ã.")
    
    # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏ –±–æ—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π —Ü–∏–∫–ª–∞
    if bot and bot.session and not bot.session.closed:
        logger.info("–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏ –±–æ—Ç–∞...")
        await bot.session.close()
        logger.info("–°–µ—Å—Å–∏—è –±–æ—Ç–∞ –∑–∞–∫—Ä—ã—Ç–∞.")

    if loop.is_running(): # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–∏–∫–ª –≤—Å–µ –µ—â–µ –∑–∞–ø—É—â–µ–Ω
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ event loop...")
        loop.stop()

async def main():
    logger.info("--- üöÄ –ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞ ---")
    create_pid_file()
    loop = asyncio.get_event_loop()
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, lambda s=sig: asyncio.create_task(shutdown(s, loop)))

    get_drive_service_sync()
    if not drive_service_instance:
        logger.critical("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: Google Drive –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
        remove_pid_files(); return

    await load_silence_state_from_file()
    await _initialize_active_vector_collection_telegram()
    
    if ADMIN_USER_ID: # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∞–¥–º–∏–Ω –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        logger.info("–ó–∞–ø—É—Å–∫ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–ó (TG)...")
        asyncio.create_task(run_update_and_notify_telegram(ADMIN_USER_ID))

    dp.include_router(router) 
    cleanup_task = asyncio.create_task(periodic_cleanup_telegram())
    daily_update_db_task = asyncio.create_task(daily_database_update_telegram())
    
    logger.info("ü§ñ Telegram –±–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")
    logger.info(f"üîá –ú–æ–ª—á–∞–Ω–∏–µ –¥–ª—è —á–∞—Ç–æ–≤: {list(chat_silence_state.keys())}")

    try:
        await dp.start_polling(bot)
    except asyncio.CancelledError: logger.info("–û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ dp.start_polling –æ—Ç–º–µ–Ω–µ–Ω–∞.")
    except Exception as e: logger.critical(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê start_polling: {e}", exc_info=True)
    finally:
        logger.info("--- üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã Telegram –±–æ—Ç–∞ (–∏–∑ finally main) ---")
        # –û—Ç–º–µ–Ω–∞ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á, –µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ –Ω–µ –±—ã–ª–∏ –æ—Ç–º–µ–Ω–µ–Ω—ã —á–µ—Ä–µ–∑ shutdown
        if cleanup_task and not cleanup_task.done(): cleanup_task.cancel()
        if daily_update_db_task and not daily_update_db_task.done(): daily_update_db_task.cancel()
        
        # –î–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ—Ç–º–µ–Ω—ã
        await asyncio.gather(cleanup_task, daily_update_db_task, return_exceptions=True)

        # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏ (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ shutdown –Ω–µ –±—ã–ª –≤—ã–∑–≤–∞–Ω –∏–ª–∏ –Ω–µ —É—Å–ø–µ–ª)
        if bot and bot.session and not bot.session.closed:
            logger.info("–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏ –±–æ—Ç–∞ (–∏–∑ finally main)...")
            await bot.session.close()
            logger.info("–°–µ—Å—Å–∏—è –±–æ—Ç–∞ –∑–∞–∫—Ä—ã—Ç–∞ (–∏–∑ finally main).")
            
        remove_pid_files()
        logger.info("--- Telegram –±–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ---")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit): logger.info("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω (KeyboardInterrupt/SystemExit).")
    except Exception as e: logger.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ù–ï–ü–ï–†–ï–•–í–ê–ß–ï–ù–ù–ê–Ø –û–®–ò–ë–ö–ê –ó–ê–ü–£–°–ö–ê: {e}", exc_info=True)
    finally: logger.info("–ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω.")